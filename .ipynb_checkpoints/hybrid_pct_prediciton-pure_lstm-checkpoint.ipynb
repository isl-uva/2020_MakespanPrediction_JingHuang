{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product Competion Time Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "The data is given in recurrent sequence. We fill the data to the maximum possible length.\n",
    "\n",
    "- **x_node_type**: The type of each recurrent units, 0-machine, 1-product\n",
    "- **x_node_feature**: The feature for each recurrent units\n",
    "- **y_location**: The lower bound given by system model\n",
    "- **y_makespan**: The PCT for each product\n",
    "\n",
    "The data is collected from the system with the following parameters:\n",
    "- **Machine Number**: 8\n",
    "- **Buffer Capacities**: 5 for each machine\n",
    "- **Incoming Products Included**: 5\n",
    "- **Total Prodcut Types**: 10\n",
    "\n",
    "The total number of datapoints is 10,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: 10000 datapoints loaded\n"
     ]
    }
   ],
   "source": [
    "# The maximum length of a recurrent sequence input is 48\n",
    "d0 = 10000\n",
    "d1 = 48\n",
    "# Data directory\n",
    "d = './dataset'\n",
    "\n",
    "# Import x_node_type\n",
    "with open(d+'/x_node_type.json', 'r') as fname:\n",
    "    temp = json.load(fname)\n",
    "    x_typ = np.zeros((d0, d1, 1))\n",
    "    for i in range(d0):\n",
    "        for j in range(len(temp[i])):\n",
    "            x_typ[i, j] = temp[i][j]\n",
    "\n",
    "# Import x_node_feature\n",
    "with open(d+'/x_node_feature.json', 'r') as fname:\n",
    "    temp = json.load(fname)\n",
    "    x_ftr = np.zeros((d0, d1, 10))\n",
    "    for i in range(d0):\n",
    "        for j in range(len(temp[i])):\n",
    "            x_ftr[i, j, :] = temp[i][j]\n",
    "            if x_typ[i, j] == 1:\n",
    "                x_ftr[i, j, :] /= 5\n",
    "\n",
    "\n",
    "            \n",
    "# Import y_location                \n",
    "with open(d+'/y_location.json', 'r') as fname:\n",
    "    temp = json.load(fname)\n",
    "    y_loc = np.zeros((d0, d1, 1))\n",
    "    for i in range(d0):\n",
    "        for j in range(len(temp[i])):\n",
    "            y_loc[i, j] = temp[i][j]\n",
    "\n",
    "# Import y_makespan           \n",
    "with open(d+'/y_makespan.json', 'r') as fname:\n",
    "    temp = json.load(fname)\n",
    "    y_mkp = np.zeros((d0, d1, 1))\n",
    "    for i in range(d0):\n",
    "        for j in range(len(temp[i])):\n",
    "            y_mkp[i, j] = temp[i][j]\n",
    "            \n",
    "\n",
    "print(\"Success: %g datapoints loaded\" % len(y_loc))\n",
    "\n",
    "# y_lstm is the output of the LSTM\n",
    "# We only predict the distance between lower bound and PCT\n",
    "y_lstm = y_mkp - y_loc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset\n",
    "Split the data by a 70:30 ratio to trainset and testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for shuffling data\n",
    "def shuffle(arr, N, seed=123):\n",
    "    idx = np.arange(N)\n",
    "    RD = np.random.RandomState(seed)\n",
    "    RD.shuffle(idx)\n",
    "    \n",
    "    res = []\n",
    "    for data in arr:\n",
    "        res.append(data[idx])\n",
    "    \n",
    "    return res\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of data points\n",
    "N = len(x_typ)\n",
    "\n",
    "[x_ftr, x_typ, y_lstm, y_loc, y_mkp] = shuffle([x_ftr, x_typ, y_lstm, y_loc, y_mkp], N)\n",
    "\n",
    "N_train = int(N * 0.7)\n",
    "\n",
    "traindata = [[x_ftr[:N_train], x_typ[:N_train]], y_lstm[:N_train]]\n",
    "testdata = [[x_ftr[N_train:], x_typ[N_train:]], y_lstm[N_train:]]\n",
    "\n",
    "test_loc = y_loc[N_train:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consturct Computation Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function for Training\n",
    "Since we fill the data with zeros, we need to exclude those positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y_pred, y_true):\n",
    "    mse = tf.reduce_mean((y_pred[y_pred!=0] - y_true[y_pred!=0])**2)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "lstm_units = 128\n",
    "dense_units = 128\n",
    "reg_l1, reg_l2 = 0.08, 0.1\n",
    "epochs = 200\n",
    "batch_size = 32\n",
    "dropout = 0.2\n",
    "\n",
    "input1 = tf.keras.Input(shape=(d1, 10), name='node_feature')\n",
    "mask = tf.keras.Input(shape=(d1, 1), name='node_type')\n",
    "\n",
    "# First LSTM layer\n",
    "h1 = tf.keras.layers.LSTM(lstm_units,\n",
    "                          return_sequences=True,\n",
    "                          return_state=False,\n",
    "                          dropout=dropout\n",
    "                          )(input1)\n",
    "\n",
    "# Normalize the outputs for LSTM_1\n",
    "h1 = tf.keras.layers.LayerNormalization(axis=1)(h1)\n",
    "\n",
    "# Skip-level connection\n",
    "input2 = tf.keras.layers.Concatenate(axis=-1)([h1, input1])\n",
    "\n",
    "# Second LSTM layer\n",
    "h2 = tf.keras.layers.LSTM(lstm_units,\n",
    "                          return_sequences=True,\n",
    "                          return_state=False,\n",
    "                          dropout=dropout\n",
    "                          )(input2)\n",
    "\n",
    "# Normalize the outputs for LSTM_2\n",
    "h2 = tf.keras.layers.LayerNormalization(axis=1)(h2)\n",
    "\n",
    "# Skip-level connection\n",
    "input3 = tf.keras.layers.Concatenate(axis=-1)([h1, h2])\n",
    "\n",
    "# MLP layer 1\n",
    "x = tf.keras.layers.Dense(dense_units,\n",
    "                          activation='relu',\n",
    "                          kernel_regularizer=tf.keras.regularizers.l1_l2(reg_l1, reg_l2)\n",
    "                          )(input3)\n",
    "\n",
    "# MLP layer 2\n",
    "x = tf.keras.layers.Dense(dense_units,\n",
    "                          activation='relu',\n",
    "                          kernel_regularizer=tf.keras.regularizers.l1_l2(reg_l1, reg_l2)\n",
    "                          )(x)\n",
    "# MLP layer 3\n",
    "x = tf.keras.layers.Dense(dense_units,\n",
    "                          activation='relu',\n",
    "                          kernel_regularizer=tf.keras.regularizers.l1_l2(reg_l1, reg_l2)\n",
    "                          )(x)\n",
    "\n",
    "# Output layer\n",
    "x = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "# Mask output for machine units and null units\n",
    "y = tf.keras.layers.multiply([x, mask])\n",
    "\n",
    "# Assemble Model\n",
    "model = tf.keras.Model(inputs=[input1, mask], outputs=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "The RMSprop is used, with learning rate adapted to 0.0001\n",
    "\n",
    "Gradient clipping is used to avoid gradient explosion\n",
    "\n",
    "Gradient clipped by [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = tf.keras.optimizers.RMSprop(learning_rate=0.0001, rho=0.9, momentum=0.0, epsilon=1e-07, clipvalue=1.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Compiling and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optim,\n",
    "              loss=loss_fn,\n",
    "              metrics=[tf.keras.metrics.MeanAbsoluteError(),\n",
    "                       tf.keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "# Early stopping\n",
    "# callback = tf.keras.callbacks.EarlyStopping(monitor='val_root_mean_square', patience=20)\n",
    "\n",
    "# Training\n",
    "hist = model.fit(x=traindata[0], y=traindata[1], validation_data=testdata, verbose=0, epochs=epochs, batch_size=batch_size) #, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hist.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=[10, 5], dpi=300)\n",
    "plt.plot(hist.history['loss'], color='red')\n",
    "plt.plot(hist.history['val_loss'], linestyle=':', color='b')\n",
    "\n",
    "plt.legend(['Train Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.savefig('Training_process.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(hist.history['root_mean_squared_error'])\n",
    "plt.plot(hist.history['val_root_mean_squared_error'])\n",
    "\n",
    "plt.legend(['train', 'test'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCT Prediction Showcase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predicted Value\n",
    "y_pred = model.predict(x=testdata[0])\n",
    "y_pred = y_pred\n",
    "\n",
    "# Mask\n",
    "y_mask = testdata[0][1]\n",
    "# Actual Value\n",
    "y_real = testdata[1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_prediction(idx):\n",
    "    xx = [x for x in range(48) if testdata[0][1][idx][x] == 1 ]\n",
    "\n",
    "    yy_pred = (y_pred[idx] + test_loc[idx])[testdata[0][1][idx] == 1]\n",
    "\n",
    "    yy_real = (y_real[idx] + test_loc[idx])[testdata[0][1][idx] == 1]\n",
    "\n",
    "    yy_loc = test_loc[idx][testdata[0][1][idx] == 1]\n",
    "\n",
    "    #plt.figure(figsize=[10, 5], dpi=400)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15,7), dpi=200)\n",
    "\n",
    "\n",
    "    ax.plot(xx, yy_pred, marker='o')\n",
    "    ax.plot(xx, yy_real, marker='s')\n",
    "    ax.plot(xx, yy_loc, marker='d')\n",
    "    ax.legend(['Predicted PCT', 'Real PCT', 'PCT Bound'], fontsize = 15.0)\n",
    "\n",
    "    ax.set_ylabel('Time', fontsize = 15.0)\n",
    "    ax.set_xlabel('Product', fontsize = 15.0)\n",
    "\n",
    "    for tick in ax.xaxis.get_major_ticks():\n",
    "        tick.label.set_fontsize(15)\n",
    "    for tick in ax.yaxis.get_major_ticks():\n",
    "        tick.label.set_fontsize(15) \n",
    "\n",
    "    ax.invert_xaxis()\n",
    "\n",
    "    fig.savefig('prediction.png')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 128\n",
    "\n",
    "idx = np.random.choice(3000)\n",
    "plot_prediction(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow = 4\n",
    "ncol = 3\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrow, ncol, figsize=(18,15), dpi=200)\n",
    "RD = np.random.RandomState(seed=966)\n",
    "idx_grid = RD.choice(3000, (nrow, ncol), replace=False)\n",
    "\n",
    "plot_idx = 1\n",
    "for i in range(nrow):\n",
    "    for j in range(ncol):\n",
    "        idx = idx_grid[i, j]\n",
    "        \n",
    "        xx = [x for x in range(48) if testdata[0][1][idx][x] == 1 ]\n",
    "\n",
    "        yy_pred = (y_pred[idx] + test_loc[idx])[testdata[0][1][idx] == 1]\n",
    "\n",
    "        yy_real = (y_real[idx] + test_loc[idx])[testdata[0][1][idx] == 1]\n",
    "\n",
    "        yy_loc = test_loc[idx][testdata[0][1][idx] == 1]\n",
    "\n",
    "        ax[i, j].plot(xx, yy_pred, marker='o')\n",
    "        ax[i, j].plot(xx, yy_real, marker='s')\n",
    "        ax[i, j].plot(xx, yy_loc, marker='d')\n",
    "        ax[i, j].set_title(idx)\n",
    "        plot_idx += 1\n",
    "        #ax[i, j].legend(['Predicted PCT', 'Real PCT', 'PCT Bound'], fontsize = 15.0)\n",
    "\n",
    "        #ax[i, j].set_ylabel('Time', fontsize = 15.0)\n",
    "        #ax[i, j].set_xlabel('Product', fontsize = 15.0)\n",
    "\n",
    "        #for tick in ax[i, j].xaxis.get_major_ticks():\n",
    "        #    tick.label.set_fontsize(15)\n",
    "        #for tick in ax[i, j].yaxis.get_major_ticks():\n",
    "        #    tick.label.set_fontsize(15) \n",
    "\n",
    "        ax[i, j].invert_xaxis()\n",
    "\n",
    "\n",
    "fig.show()\n",
    "fig.savefig('prediction_grid.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow = 4\n",
    "ncol = 3\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrow, ncol, figsize=(15,15), dpi=200)\n",
    "RD = np.random.RandomState(seed=66)\n",
    "idx_grid = RD.choice(3000, (nrow, ncol), replace=False)\n",
    "\n",
    "idx_grid = np.array([[2666, 1315, 2350],\n",
    "                     [2337, 497, 157],\n",
    "                     [2900, 239, 1109],\n",
    "                     [2049, 1212, 1152]])\n",
    "\n",
    "plot_idx = 1\n",
    "for i in range(nrow):\n",
    "    for j in range(ncol):\n",
    "        idx = idx_grid[i, j]\n",
    "        \n",
    "        xx = [x for x in range(48) if testdata[0][1][idx][x] == 1 ]\n",
    "\n",
    "        yy_pred = (y_pred[idx] + test_loc[idx])[testdata[0][1][idx] == 1]\n",
    "\n",
    "        yy_real = (y_real[idx] + test_loc[idx])[testdata[0][1][idx] == 1]\n",
    "\n",
    "        yy_loc = test_loc[idx][testdata[0][1][idx] == 1]\n",
    "\n",
    "        ax[i, j].plot(xx, yy_pred, marker='o')\n",
    "        ax[i, j].plot(xx, yy_real, marker='s')\n",
    "        ax[i, j].plot(xx, yy_loc, marker='d')\n",
    "        ax[i, j].set_title(plot_idx)\n",
    "        plot_idx += 1\n",
    "        # ax[i, j].legend(['Predicted PCT', 'Real PCT', 'PCT Bound'])\n",
    "\n",
    "        ax[i, j].set_ylabel('Time')\n",
    "        ax[i, j].set_xlabel('Products')\n",
    "        ax[i, j].xaxis.set_label_coords(0.5, 0.1)\n",
    "\n",
    "        #for tick in ax[i, j].xaxis.get_major_ticks():\n",
    "        #    tick.label.set_fontsize(15)\n",
    "        #for tick in ax[i, j].yaxis.get_major_ticks():\n",
    "        #    tick.label.set_fontsize(15)\n",
    "        \n",
    "        ax[i, j].tick_params(axis = \"x\", which = \"both\", bottom = False, top = False)\n",
    "        ax[i, j].set_xticklabels([])\n",
    "        ax[i, j].invert_xaxis()\n",
    "\n",
    "\n",
    "fig.show()\n",
    "fig.savefig('prediction_grid.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = np.mean(np.abs(y_pred[y_mask!=0] - y_real[y_mask!=0]))\n",
    "print(\"Mean Absolute Error: %g\" % mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape = np.mean(np.abs((y_real[y_mask!=0] - y_pred[y_maskl!=0]) / y_real[y_mask!=0]))\n",
    "print(\"Mean Absolute Percentage Error: %g%%\" % (mape*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = np.mean((y_pred[y_mask!=0] - y_real[y_mask!=0]) ** 2)\n",
    "print(\"Mean Square Error: %g\" % mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(np.mean((y_pred[y_mask!=0] - y_real[y_mask!=0]) ** 2))\n",
    "print(\"Root Mean Square Error: %g\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R-square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = 1 - np.sum((y_real[y_mask!=0] - y_pred[y_mask!=0]) ** 2) / np.sum((np.mean(y_real[y_mask!=0]) - y_real[y_mask!=0]) ** 2)\n",
    "print(\"R2: %g\" % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow 2.1/Keras Py3.7",
   "language": "python",
   "name": "tensorflow210_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
