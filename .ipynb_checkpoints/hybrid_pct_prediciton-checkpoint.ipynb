{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product Competion Time Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "The data is given in recurrent sequence. We fill the data to the maximum possible length.\n",
    "\n",
    "- **x_node_type**: The type of each recurrent units, 0-machine, 1-product\n",
    "- **x_node_feature**: The feature for each recurrent units\n",
    "- **y_location**: The lower bound given by system model\n",
    "- **y_makespan**: The PCT for each product\n",
    "\n",
    "The data is collected from the system with the following parameters:\n",
    "- **Machine Number**: 8\n",
    "- **Buffer Capacities**: 5 for each machine\n",
    "- **Incoming Products Included**: 5\n",
    "- **Total Prodcut Types**: 10\n",
    "\n",
    "The total number of datapoints is 10,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result, async_)\u001b[0m\n\u001b[1;32m   3330\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3331\u001b[0;31m                     \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_global_ns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3332\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-c874b5e9957a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx_typ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                 \u001b[0mx_ftr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmach_ftr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx_ftr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m                 \u001b[0mm\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result, async_)\u001b[0m\n\u001b[1;32m   3338\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3339\u001b[0m             \u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"To exit: use 'exit', 'quit', or Ctrl-D.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3340\u001b[0;31m         \u001b[0;32mexcept\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustom_exceptions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3341\u001b[0m             \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3342\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# The maximum length of a recurrent sequence input is 48\n",
    "d0 = 10000\n",
    "d1 = 48\n",
    "# Data directory\n",
    "d = './data'\n",
    "\n",
    "# Import x_node_type\n",
    "with open(d+'/x_node_type.json', 'r') as fname:\n",
    "    temp = json.load(fname)\n",
    "    x_typ = np.zeros((d0, d1, 1))\n",
    "    for i in range(d0):\n",
    "        for j in range(len(temp[i])):\n",
    "            x_typ[i, j] = temp[i][j]\n",
    "\n",
    "# Import x_node_feature\n",
    "temp = []\n",
    "for i in range(1,6):\n",
    "    with open(d+'/x_node_feature_%g.json'%i, 'r') as fname:\n",
    "        temp += json.load(fname)\n",
    "\n",
    "# Pre-process x_node_type        \n",
    "x_ftr = np.zeros((d0, d1, 10))\n",
    "mach_ftr = np.zeros((d0, 8))\n",
    "for i in range(d0):\n",
    "    mach_idx = 1\n",
    "    mach = []\n",
    "    first_prod = True\n",
    "    for j in range(len(temp[i])):\n",
    "        if x_typ[i, j, 0] == 1:\n",
    "\n",
    "            x_ftr[i, j] = temp[i][j]\n",
    "            x_ftr[i, j] /= 5\n",
    "\n",
    "            if first_prod:\n",
    "                # if this is the 1st product encountered\n",
    "                for m in mach:\n",
    "                    mach_ftr[i, -m] = x_ftr[i, j, -m]\n",
    "\n",
    "            first_prod = False\n",
    "            mach = []\n",
    "\n",
    "        elif x_typ[i, j, 0] == 0:\n",
    "            # This is a machine\n",
    "            mach.append(mach_idx)\n",
    "            mach_idx += 1\n",
    "            x_ftr[i, j] = temp[i][j]\n",
    "            first_prod = True\n",
    "\n",
    "    for i in range(d0):\n",
    "        m = 1\n",
    "        for j in range(len(temp[i])):\n",
    "            if x_typ[i, j, 0] == 0:\n",
    "                x_ftr[i, j, 1] = mach_ftr[i, -m] * (1 - x_ftr[i, j, 1])\n",
    "                m += 1\n",
    "\n",
    "            \n",
    "# Import y_location                \n",
    "with open(d+'/y_location.json', 'r') as fname:\n",
    "    temp = json.load(fname)\n",
    "    y_loc = np.zeros((d0, d1, 1))\n",
    "    for i in range(d0):\n",
    "        for j in range(len(temp[i])):\n",
    "            y_loc[i, j] = temp[i][j]\n",
    "\n",
    "# Import y_makespan           \n",
    "with open(d+'/y_makespan.json', 'r') as fname:\n",
    "    temp = json.load(fname)\n",
    "    y_mkp = np.zeros((d0, s1, 1))\n",
    "    for i in range(d0):\n",
    "        for j in range(len(temp[i])):\n",
    "            y_mkp[i, j] = temp[i][j]\n",
    "            \n",
    "\n",
    "print(\"Success: %g datapoints loaded\" % len(y_loc))\n",
    "\n",
    "# y_lstm is the output of the LSTM\n",
    "# We only predict the distance between lower bound and PCT\n",
    "y_lstm = y_mkp - y_loc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset\n",
    "Split the data by a 70:30 ratio to trainset and testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for shuffling data\n",
    "def shuffle(arr, N, seed=123):\n",
    "    idx = np.arange(N)\n",
    "    RD = np.random.RandomState(seed)\n",
    "    RD.shuffle(idx)\n",
    "    \n",
    "    res = []\n",
    "    for data in arr:\n",
    "        res.append(data[idx])\n",
    "    \n",
    "    return res\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of data points\n",
    "N = len(x_typ)\n",
    "\n",
    "[x_ftr, x_typ, y_lstm, y_loc, y_mkp] = shuffle([x_ftr, x_typ, y_lstm, y_loc, y_mkp], N)\n",
    "\n",
    "N_train = int(N * 0.7)\n",
    "\n",
    "traindata = [[x_ftr[:N_train], x_typ[:N_train]], y_lstm[:N_train]]\n",
    "testdata = [[x_ftr[N_train:], x_typ[N_train:]], y_lstm[N_train:]]\n",
    "\n",
    "test_loc = y_loc[N_train:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consturct Computation Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function for Training\n",
    "Since we fill the data with zeros, we need to exclude those positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y_pred, y_true):\n",
    "    mse = tf.reduce_mean((y_pred[y_true!=0] - y_true[y_true!=0])**2)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "lstm_units = 128\n",
    "dense_units = 128\n",
    "reg_l1, reg_l2 = 0.08, 0.1\n",
    "epochs = 200\n",
    "batch_size = 32\n",
    "dropout = 0.2\n",
    "\n",
    "input1 = tf.keras.Input(shape=(d1, 10), name='node_feature')\n",
    "mask = tf.keras.Input(shape=(d1, 1), name='node_type')\n",
    "\n",
    "# First LSTM layer\n",
    "h1 = tf.keras.layers.LSTM(lstm_units,\n",
    "                          return_sequences=True,\n",
    "                          return_state=False,\n",
    "                          dropout=dropout\n",
    "                          )(input1)\n",
    "\n",
    "# Normalize the outputs for LSTM_1\n",
    "h1 = tf.keras.layers.LayerNormalization(axis=1)(h1)\n",
    "\n",
    "# Skip-level connection\n",
    "input2 = tf.keras.layers.Concatenate(axis=-1)([h1, input1])\n",
    "\n",
    "# Second LSTM layer\n",
    "h2 = tf.keras.layers.LSTM(lstm_units,\n",
    "                          return_sequences=True,\n",
    "                          return_state=False,\n",
    "                          dropout=dropout\n",
    "                          )(input2)\n",
    "\n",
    "# Normalize the outputs for LSTM_2\n",
    "h2 = tf.keras.layers.LayerNormalization(axis=1)(h2)\n",
    "\n",
    "# Skip-level connection\n",
    "input3 = tf.keras.layers.Concatenate(axis=-1)([h1, h2])\n",
    "\n",
    "# MLP layer 1\n",
    "x = tf.keras.layers.Dense(dense_units,\n",
    "                          activation='relu',\n",
    "                          kernel_regularizer=tf.keras.regularizers.l1_l2(reg_l1, reg_l2)\n",
    "                          )(input3)\n",
    "\n",
    "# MLP layer 2\n",
    "x = tf.keras.layers.Dense(dense_units,\n",
    "                          activation='relu',\n",
    "                          kernel_regularizer=tf.keras.regularizers.l1_l2(reg_l1, reg_l2)\n",
    "                          )(x)\n",
    "# MLP layer 3\n",
    "x = tf.keras.layers.Dense(dense_units,\n",
    "                          activation='relu',\n",
    "                          kernel_regularizer=tf.keras.regularizers.l1_l2(reg_l1, reg_l2)\n",
    "                          )(x)\n",
    "\n",
    "# Output layer\n",
    "x = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "# Mask output for machine units and null units\n",
    "y = tf.keras.layers.multiply([x, mask])\n",
    "\n",
    "# Assemble Model\n",
    "model = tf.keras.Model(inputs=[input1, mask], outputs=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "The RMSprop is used, with learning rate adapted to 0.0001\n",
    "\n",
    "Gradient clipping is used to avoid gradient explosion\n",
    "\n",
    "Gradient clipped by [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = tf.keras.optimizers.RMSprop(learning_rate=0.0001, rho=0.9, momentum=0.0, epsilon=1e-07, clipvalue=1.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Compiling and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optim,\n",
    "              loss=loss_fn,\n",
    "              metrics=[tf.keras.metrics.MeanAbsoluteError(),\n",
    "                       tf.keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "# Early stopping\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_root_mean_square', patience=20)\n",
    "\n",
    "# Training\n",
    "hist = model.fit(x=traindata[0], y=traindata[1], validation_data=testdata, verbose=1, epochs=epochs, batch_size=batch_size, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hist.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=[10, 5], dpi=300)\n",
    "plt.plot(hist.history['loss'])#[:101])\n",
    "plt.plot(hist.history['val_loss'])#[:101])\n",
    "\n",
    "plt.legend(['Train Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.savefig('Training_process.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root Mean Square Error\n",
    "Remark: This RMSE is not equal to the true RMSE since the model include the null units masked out. But the trend remains the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(hist.history['root_mean_squared_error'])\n",
    "plt.plot(hist.history['val_root_mean_squared_error'])\n",
    "\n",
    "plt.legend(['train', 'test'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCT Prediction Showcase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predicted Value\n",
    "y_pred = model.predict(x=testdata[0])\n",
    "y_pred = y_pred\n",
    "\n",
    "# Actual Value\n",
    "y_real = testdata[1]\n",
    "\n",
    "idx = 128\n",
    "\n",
    "xx = [x for x in range(48) if testdata[0][1][idx][x] == 1 ]\n",
    "\n",
    "yy_pred = (y_pred[idx] + test_loc[idx])[testdata[0][1][idx] == 1]\n",
    "\n",
    "yy_real = (y_real[idx] + test_loc[idx])[testdata[0][1][idx] == 1]\n",
    "\n",
    "yy_loc = test_loc[idx][testdata[0][1][idx] == 1]\n",
    "\n",
    "#plt.figure(figsize=[10, 5], dpi=400)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,7), dpi=200)\n",
    "\n",
    "\n",
    "ax.plot(xx, yy_pred, marker='o')\n",
    "ax.plot(xx, yy_real, marker='s')\n",
    "ax.plot(xx, yy_loc, marker='d')\n",
    "ax.legend(['Predicted PCT', 'Real PCT', 'PCT Bound'], fontsize = 15.0)\n",
    "\n",
    "ax.set_ylabel('Time', fontsize = 15.0)\n",
    "ax.set_xlabel('Product', fontsize = 15.0)\n",
    "\n",
    "for tick in ax.xaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(15)\n",
    "for tick in ax.yaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(15) \n",
    "        \n",
    "    ax.invert_xaxis()\n",
    "\n",
    "fig.savefig('prediction.png')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = np.mean(np.abs(y_pred[y_real!=0] - y_real[y_real!=0]))\n",
    "print(\"Mean Absolute Error: %g\" % mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape = np.mean(np.abs((y_real[y_real!=0] - y_pred[y_real!=0]) / y_real[y_real!=0]))\n",
    "print(\"Mean Absolute Percentage Error: %g%%\" % (mape*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = np.mean((y_pred[y_real!=0] - y_real[y_real!=0]) ** 2)\n",
    "print(\"Mean Square Error: %g\" % mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(np.mean((y_pred[y_real!=0] - y_real[y_real!=0]) ** 2))\n",
    "print(\"Root Mean Square Error: %g\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R-square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = 1 - np.sum((y_real[y_real!=0] - y_pred[y_real!=0]) ** 2) / np.sum((np.mean(y_real[y_real!=0]) - y_real[y_real!=0]) ** 2)\n",
    "print(\"R2: %g\" % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow 2.1/Keras Py3.7",
   "language": "python",
   "name": "tensorflow210_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
